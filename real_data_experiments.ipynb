{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logistic_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(44) # for comparison of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of different optimization methods for logistic regression\n",
    "\n",
    "In the following notebook, we will compare different optimization methods for logistic regression. We will use one generated dataseta along with many real datasets. We will compare the following optimization methods:\n",
    "- IWLS (Iteratively Reweighted Least Squares)\n",
    "- SGD (Stochastic Gradient Descent)\n",
    "- ADAM (Adaptive Moment Estimation)\n",
    "\n",
    "We will also compare the performance of the optimization methods using interactions between features and without.\n",
    "\n",
    "The parameters of the optimization methods are choosen to be default for each method:\n",
    "\n",
    "## Stopping criterion\n",
    "\n",
    "To make a comparison fair, we propose the same stopping rule for each algorithm.\n",
    "We will stop the optimization when the values of the gradient are less than 1^{-3} or when the number of iterations is greater than 100.\n",
    "\n",
    "CONSIDER DIFFERENT STOPPING RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(X, y, algorithms = [\"iwls\", \"sgd\", \"adam\"], k = 5, test_size = 0.2, interaction = False):\n",
    "    balanced_accuracies = {}\n",
    "    interaction_opt = [False]\n",
    "    if interaction:\n",
    "        interaction_opt.append(True)\n",
    "\n",
    "    for alg in algorithms:\n",
    "        balanced_accuracies[alg] = []\n",
    "        \n",
    "        print(f\"Using algorithm: {alg}\" + (\" with interactions\" if interaction else \"\"))\n",
    "        for inter in interaction_opt:\n",
    "            alg_name = alg + (\"_inter\" if inter else \"\")\n",
    "            for i in range(k):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "                model = logistic_regression.LogisticRegressor(descent_algorithm = alg, include_interactions = inter)\n",
    "                model.fit(X_train, y_train, max_num_epoch = 100, tolerance=1e-3)\n",
    "                balanced_accuracies[alg].append(model.balanced_accuracy(X_test, y_test))\n",
    "                print(f\"Balanced accuracy: {balanced_accuracies[alg_name][-1]}\")\n",
    "            print(f\"Mean accuracy: {np.mean(balanced_accuracies[alg_name])}\")\n",
    "    balanced_accuracies = pd.DataFrame(balanced_accuracies)\n",
    "    return balanced_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "n = 1000\n",
    "\n",
    "a = 10\n",
    "\n",
    "# Generate y observations from the binomial distribution\n",
    "y = np.random.binomial(1, 0.5, size=n)\n",
    "\n",
    "true_beta = np.array([5, 3])\n",
    "\n",
    "X = np.random.normal(size = (n, 2))\n",
    "\n",
    "y = np.random.binomial(1, sigmoid(X @ true_beta))\n",
    "\n",
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm: iwls\n",
      "Balanced accuracy: 0.9150660264105642\n",
      "Balanced accuracy: 0.8956582633053222\n",
      "Balanced accuracy: 0.8896025692492975\n",
      "Balanced accuracy: 0.9138522028430285\n",
      "Balanced accuracy: 0.9046474358974359\n",
      "Mean accuracy: 0.9037652995411296\n",
      "Using algorithm: sgd\n",
      "Balanced accuracy: 0.9058623449379752\n",
      "Balanced accuracy: 0.9293717486994798\n",
      "Balanced accuracy: 0.9121212121212121\n",
      "Balanced accuracy: 0.9091636654661864\n",
      "Balanced accuracy: 0.9211614073999395\n",
      "Mean accuracy: 0.9155360757249585\n",
      "Using algorithm: adam\n",
      "Balanced accuracy: 0.930172068827531\n",
      "Balanced accuracy: 0.92\n",
      "Balanced accuracy: 0.9426561392853527\n",
      "Balanced accuracy: 0.8780623046678093\n",
      "Balanced accuracy: 0.9210950080515299\n",
      "Mean accuracy: 0.9183971041664446\n"
     ]
    }
   ],
   "source": [
    "df = compare_methods(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aids = pd.read_csv('data/aids.csv')\n",
    "\n",
    "y = aids['target']\n",
    "X = aids.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm: iwls\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mcompare_methods\u001b[1;34m(X, y, algorithms)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing algorithm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m logistic_regression\u001b[38;5;241m.\u001b[39mLogisticRegressor(descent_algorithm \u001b[38;5;241m=\u001b[39m alg)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mbalanced_accuracy(X,\u001b[38;5;250m \u001b[39my)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\studia\\sem6\\advml\\pro\\logistic_regression\\logistic_regression\\regressor.py:164\u001b[0m, in \u001b[0;36mLogisticRegressor.fit\u001b[1;34m(self, X, y, learning_rate, max_num_epoch, tolerance, batch_size, verbose)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m mini_batch_gd(\n\u001b[0;32m    152\u001b[0m         X_copy,\n\u001b[0;32m    153\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescent_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miwls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m \u001b[43miwls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_num_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescent_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m adam(\n\u001b[0;32m    174\u001b[0m         X_copy,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    182\u001b[0m     )\n",
      "File \u001b[1;32md:\\studia\\sem6\\advml\\pro\\logistic_regression\\logistic_regression\\optimizers.py:156\u001b[0m, in \u001b[0;36miwls\u001b[1;34m(X, y, initial_solution, max_num_epoch, tolerance, epsilon, verbose)\u001b[0m\n\u001b[0;32m    154\u001b[0m P \u001b[38;5;241m=\u001b[39m sigmoid(X \u001b[38;5;241m@\u001b[39m current_solution)\n\u001b[0;32m    155\u001b[0m W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(P \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m P))\n\u001b[1;32m--> 156\u001b[0m Z \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m current_solution \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m P)\n\u001b[0;32m    157\u001b[0m H \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m W \u001b[38;5;241m@\u001b[39m X\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# prevent singular matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tymot\\anaconda3\\envs\\prod\\lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\tymot\\anaconda3\\envs\\prod\\lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "compare_methods(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m logistic_regression\u001b[38;5;241m.\u001b[39mLogisticRegressor(descent_algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m lr\u001b[38;5;241m.\u001b[39mconfusion_matrix(X_test, y_test)\n",
      "File \u001b[1;32md:\\studia\\sem6\\advml\\pro\\logistic_regression\\logistic_regression\\regressor.py:180\u001b[0m, in \u001b[0;36mLogisticRegressor.fit\u001b[1;34m(self, X, y, learning_rate, max_num_epoch, batch_size, verbose)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m adam(\n\u001b[0;32m    171\u001b[0m         X_copy,\n\u001b[0;32m    172\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescent_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLogisticRegressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_prime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_num_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescent_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m newton(\n\u001b[0;32m    191\u001b[0m         X_copy,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32md:\\studia\\sem6\\advml\\pro\\logistic_regression\\logistic_regression\\optimizers.py:204\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(X, y, initial_solution, calculate_gradient, learning_rate, max_num_epoch, tolerance, verbose)\u001b[0m\n\u001b[0;32m    202\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X[shuffled_idx], y[shuffled_idx]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_selected, y_selected \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, y):\n\u001b[1;32m--> 204\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_solution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     current_solution \u001b[38;5;241m=\u001b[39m current_solution \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradient\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32md:\\studia\\sem6\\advml\\pro\\logistic_regression\\logistic_regression\\regressor.py:106\u001b[0m, in \u001b[0;36mLogisticRegressor.loss_prime\u001b[1;34m(X, y, beta)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_prime\u001b[39m(\n\u001b[0;32m     99\u001b[0m     X: Union[np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mDataFrame],\n\u001b[0;32m    100\u001b[0m     y: Union[np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mDataFrame],\n\u001b[0;32m    101\u001b[0m     beta: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    102\u001b[0m ):\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    calculates the derivative of the loss function with respect to the beta\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    107\u001b[0m         beta\n\u001b[0;32m    108\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features in X must match the length of beta, maybe try adding an intercept or interaction terms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# as we know from MSO\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     p \u001b[38;5;241m=\u001b[39m sigmoid(X \u001b[38;5;241m@\u001b[39m beta)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "lr = logistic_regression.LogisticRegressor(descent_algorithm=\"sgd\")\n",
    "\n",
    "lr.fit(X_train, y_train, max_num_epoch=100)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.confusion_matrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'trt', 'age', 'wtkg', 'hemo', 'homo', 'drugs', 'karnof',\n",
       "       'oprior', 'z30', 'preanti', 'race', 'gender', 'symptom', 'treat',\n",
       "       'offtrt', 'cd40', 'cd420', 'cd80', 'cd820'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lr = LogisticRegression(max_iter=10000, tol=1e-3, solver='lbfgs')\n",
    "sklearn_lr.fit(X, y)\n",
    "sklearn_lr.score(X, y)\n",
    "y_pred = sklearn_lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our implementation\n",
      "[[ 182   73]\n",
      " [ 339 1545]]\n",
      "Sklearn implementation\n",
      "[[1531   87]\n",
      " [ 190  331]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our implementation\\n{lr.confusion_matrix(X, y)}\")\n",
    "print(f\"Sklearn implementation\\n{confusion_matrix(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our implementation: 0.8130841121495327\n",
      "Accuracy of sklearn implementation: 0.8808411214953271\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of our implementation: {lr.accuracy(X_test, y_test)}\")\n",
    "print(f\"Accuracy of sklearn implementation: {sklearn_lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asseco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
